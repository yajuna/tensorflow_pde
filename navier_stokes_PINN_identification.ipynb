{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBklgnenY+lxBfm12wnlya",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yajuna/tensorflow_pde/blob/master/navier_stokes_PINN_identification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This work is based on the methodology originally developed by [Raissi](https://github.com/maziarraissi/PINNs/blob/master/main/continuous_time_identification%20(Navier-Stokes)/NavierStokes.py), and the Tensorflow 2.0 modification by [Blechschmidt](https://github.com/janblechschmidt/PDEsByNNs) and [pierremtb ](https://github.com/pierremtb/PINNs-TF2.0).\n",
        "\n",
        "A Tensorflow 2.0 implementation of the inference problem for the Navier Stokes equation is [here](https://github.com/yajuna/tensorflow_pde/blob/master/navier_stokes_PINN_Solver.ipynb). This notebook is a Tensorflow 2.0 implementation of the Navier Stokes identification problem. We run this notebook with the original data provided by the author to test our implementation for the inference problem. This code is modified from [the heat identification code](https://github.com/yajuna/tensorflow_pde/blob/master/Heat_equation_with_tensorflow.ipynb)"
      ],
      "metadata": {
        "id": "VXtYqqellzJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import scipy.io\n",
        "\n",
        "from time import time\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "fuZGtDwTqSfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get data for Navier Stokes"
      ],
      "metadata": {
        "id": "rXjg964rQD_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/maziarraissi/PINNs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8exWF5rNqrPF",
        "outputId": "1e1a2f69-b573-4eb2-9cad-d2e5611f79c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'PINNs' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# \".\" for Colab/VSCode, and \"..\" for GitHub\n",
        "repoPath = os.path.join(\".\", \"PINNs\")\n",
        "# repoPath = os.path.join(\"..\", \"PINNs\")\n",
        "utilsPath = os.path.join(repoPath, \"Utilities\")\n",
        "dataPath = os.path.join(repoPath, \"main\", \"Data\")\n",
        "appDataPath = os.path.join(repoPath, \"appendix\", \"Data\")"
      ],
      "metadata": {
        "id": "WfPE290ZrG2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set data type\n",
        "DTYPE='float32'\n",
        "tf.keras.backend.set_floatx(DTYPE)\n",
        "\n",
        "# Set random seed for reproducible results\n",
        "tf.random.set_seed(0)"
      ],
      "metadata": {
        "id": "LYUP9e9v5Rug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_train = 5000\n",
        "\n",
        "path = os.path.join(dataPath, \"cylinder_nektar_wake.mat\")\n",
        "data = scipy.io.loadmat(path)\n",
        "\n",
        "# define training and testing data\n",
        "U_star = data['U_star'] # N x 2 x T\n",
        "P_star = data['p_star'] # N x T\n",
        "t_star = data['t'] # T x 1\n",
        "X_star = data['X_star'] # N x 2\n",
        "\n",
        "print('X_star start and end; t_star start and end', X_star[0], X_star[-1], t_star[0], t_star[-1])\n",
        "\n",
        "N = X_star.shape[0]\n",
        "T = t_star.shape[0]\n",
        "\n",
        "#Rearrange Data\n",
        "XX = np.tile(X_star[:,0:1], (1,T)) # N x T\n",
        "YY = np.tile(X_star[:,1:2], (1,T)) # N x T\n",
        "TT = np.tile(t_star, (1,N)).T # N x T\n",
        "\n",
        "UU = U_star[:,0,:] # N x T\n",
        "VV = U_star[:,1,:] # N x T\n",
        "PP = P_star # N x T\n",
        "\n",
        "x = XX.flatten()[:,None] # NT x 1\n",
        "y = YY.flatten()[:,None] # NT x 1\n",
        "t = TT.flatten()[:,None] # NT x 1\n",
        "\n",
        "u = UU.flatten()[:,None] # NT x 1\n",
        "v = VV.flatten()[:,None] # NT x 1\n",
        "p = PP.flatten()[:,None] # NT x 1\n",
        "\n",
        "X = tf.concat([x,y,t], axis = 1)\n",
        "data = tf.concat([u,v,p], axis = 1)\n",
        "\n",
        "######################################################################\n",
        "######################## Noiseles Data ###############################\n",
        "######################################################################\n",
        "# Training Data\n",
        "idx = np.random.choice(N*T, N_train, replace=False)\n",
        "x_train = x[idx,:]\n",
        "y_train = y[idx,:]\n",
        "t_train = t[idx,:]\n",
        "u_train = u[idx,:]\n",
        "v_train = v[idx,:]\n",
        "\n",
        "print('x_train min and max', x_train.min(), x_train.max())\n",
        "\n",
        "# Test Data\n",
        "snap = np.array([100])\n",
        "x_star = X_star[:,0:1]\n",
        "y_star = X_star[:,1:2]\n",
        "t_star = TT[:,snap]\n",
        "\n",
        "X_r = tf.concat([x_star,y_star,t_star], axis=1)\n",
        "\n",
        "u_star = U_star[:,0,snap]\n",
        "v_star = U_star[:,1,snap]\n",
        "p_star = P_star[:,snap]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ifq23Johr2J-",
        "outputId": "a9a48865-fbda-4280-8c68-dc7e880930d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_star start and end; t_star start and end [ 1. -2.] [8. 2.] [0.] [19.9]\n",
            "x_train min and max 1.0 8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ################### load data from google drive\n",
        "# \"\"\"\n",
        "# To load data from Google Drive, download data from\n",
        "# https://github.com/maziarraissi/PINNs/tree/master/main/Data\n",
        "# and save it in a folder called \"data\" in your Google drive\n",
        "# \"\"\"\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# data = scipy.io.loadmat('/content/drive/My Drive/data/cylinder_nektar_wake.mat')"
      ],
      "metadata": {
        "id": "vB6m2Fx1QIBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model architecture\n",
        "\n",
        "class PINN_NeuralNet(tf.keras.Model):\n",
        "  \"\"\"Basic architecture of the PINN model\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, lb, ub,\n",
        "               output_dim = 1,\n",
        "               num_hidden_layers = 8,\n",
        "               num_neurons_per_layer = 20,\n",
        "               activation = 'tanh',\n",
        "               kernel_initializer = 'glorot_normal',\n",
        "               **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "\n",
        "    self.num_hidden_layers = num_hidden_layers\n",
        "    self.output_dim = output_dim\n",
        "\n",
        "    self.lb = lb\n",
        "    self.ub = ub\n",
        "\n",
        "    # X = tf.concat([x,y,t], axis=1)\n",
        "    # self.lb = X.min(0)\n",
        "    # self.ub = X.max(0)\n",
        "    # self.X = X\n",
        "    # self.x = X[:,0:1]\n",
        "    # self.y = X[:,1:2]\n",
        "    # self.t = X[:,2:3]\n",
        "\n",
        "    # self.u = u\n",
        "    # self.v = v\n",
        "\n",
        "    # Define NN architecture\n",
        "    self.scale = tf.keras.layers.Lambda(\n",
        "            lambda x: 2.0*(x - self.lb)/(self.ub - self.lb) - 1.0)\n",
        "    self.hidden = [tf.keras.layers.Dense(num_neurons_per_layer,\n",
        "                             activation=tf.keras.activations.get(activation),\n",
        "                             kernel_initializer=kernel_initializer)\n",
        "                           for _ in range(self.num_hidden_layers)]\n",
        "    self.out = tf.keras.layers.Dense(output_dim)\n",
        "\n",
        "  def call(self, X):\n",
        "    \"\"\"\n",
        "    Forward-pass thru NN\n",
        "    \"\"\"\n",
        "    Z = self.scale(X)\n",
        "    for i in range(self.num_hidden_layers):\n",
        "      Z = self.hidden[i](Z)\n",
        "    return self.out(Z)"
      ],
      "metadata": {
        "id": "zYzfUI9wtBRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PINNIdentificationNet(PINN_NeuralNet):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "\n",
        "        # Call init of base class\n",
        "        super().__init__(*args,**kwargs)\n",
        "\n",
        "        # Initialize variable for lambda\n",
        "\n",
        "        self.lambd1 = tf.Variable(1.0, trainable=True, dtype=DTYPE)\n",
        "        self.lambd1_list = []\n",
        "\n",
        "        self.lambd2 = tf.Variable(1.0, trainable=True, dtype=DTYPE)\n",
        "        self.lambd2_list = []"
      ],
      "metadata": {
        "id": "MHfKtKPptIAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Major modification in PINNSolver- Change dimensions of input and output variables\n",
        "\n",
        "### to do\n",
        "- use original data from Raissi\n",
        "\n",
        "- change variable names\n",
        "\n",
        "- run on HYAK"
      ],
      "metadata": {
        "id": "sctjRp720ikd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PINNSolver():\n",
        "    def __init__(self, model, X_r):\n",
        "        self.model = model\n",
        "\n",
        "        # Store collocation points, separate t and x\n",
        "        self.x = X_r[:,0:1]\n",
        "        self.y = X_r[:,1:2]\n",
        "        self.t = X_r[:,2:3]\n",
        "\n",
        "        # Initialize history of losses and global iteration counter\n",
        "        self.hist = []\n",
        "        self.iter = 0\n",
        "\n",
        "# compute residual of PDE with results of automatic differentiation- physics information\n",
        "    def get_r(self):\n",
        "\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            # Watch variables representing t and x during this GradientTape\n",
        "            tape.watch(self.x)\n",
        "            tape.watch(self.y)\n",
        "            tape.watch(self.t)\n",
        "\n",
        "            # compute current psi and p\n",
        "            pp = self.model(tf.stack([self.x[:,0], self.y[:,0],self.t[:,0]], axis=1))\n",
        "            psi = pp[:,0:1]\n",
        "            p = pp[:,1:2]\n",
        "\n",
        "            # Compute gradients\n",
        "            u = tape.gradient(psi, self.y)\n",
        "            v = -tape.gradient(psi, self.x)\n",
        "\n",
        "            u_x = tape.gradient(u, self.x)\n",
        "            u_y = tape.gradient(u, self.y)\n",
        "\n",
        "            v_x = tape.gradient(v, self.x)\n",
        "            v_y = tape.gradient(v, self.y)\n",
        "\n",
        "\n",
        "\n",
        "        p_x = tape.gradient(p, self.x)\n",
        "        p_y = tape.gradient(p, self.y)\n",
        "\n",
        "        u_t = tape.gradient(u, self.t)\n",
        "        u_xx = tape.gradient(u_x, self.x)\n",
        "        u_yy = tape.gradient(u_y, self.y)\n",
        "\n",
        "        v_t = tape.gradient(v, self.t)\n",
        "        v_xx = tape.gradient(v_x, self.x)\n",
        "        v_yy = tape.gradient(v_y, self.y)\n",
        "\n",
        "        del tape\n",
        "\n",
        "        return self.fun_r(u, u_t, u_x, u_y, u_xx, u_yy, v, v_t, v_x, v_y, v_xx, v_yy, p_x, p_y) ########\n",
        "\n",
        "# compute loss function\n",
        "    def loss_fn(self, X, data):\n",
        "\n",
        "        # Compute phi_r from model and X_r\n",
        "        r = self.get_r()\n",
        "        phi_r = tf.reduce_mean(tf.square(r))\n",
        "\n",
        "        # Initialize loss\n",
        "        loss = phi_r\n",
        "\n",
        "        # compute loss at testing\n",
        "\n",
        "        pp_pred = self.model(X)\n",
        "        loss += tf.reduce_mean(tf.square(data - pp_pred))\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "# from the model, get model trainable variables and keep for gradient descent\n",
        "    def get_grad(self, X, data):\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            # This tape is for derivatives with\n",
        "            # respect to trainable variables\n",
        "            tape.watch(self.model.trainable_variables)\n",
        "            loss = self.loss_fn(X, data)\n",
        "\n",
        "        g = tape.gradient(loss, self.model.trainable_variables)\n",
        "        del tape\n",
        "\n",
        "        return loss, g\n",
        "\n",
        "\n",
        "    def fun_r(self, u, u_t, u_x, u_y, u_xx, u_yy, v, v_t, v_x, v_y, v_xx, v_yy, p_x, p_y):\n",
        "        \"\"\"Residual of the PDE\"\"\"\n",
        "        f = u_t + self.model.lambd1 * (u * u_x + v * u_y) + p_x - self.model.lambd2 * (u_xx + u_yy)\n",
        "        g = v_t + self.model.lambd1 * (u * v_x + v * v_y) + p_y - self.model.lambd2 * (v_xx + v_yy)\n",
        "        return tf.concat([f, g], axis=1)\n",
        "\n",
        "    def solve_with_TFoptimizer(self, optimizer, X, data, N=1001):\n",
        "        \"\"\"This method performs a gradient descent type optimization.\"\"\"\n",
        "\n",
        "        @tf.function\n",
        "        def train_step():\n",
        "            loss, grad_theta = self.get_grad(X, data)\n",
        "\n",
        "            # Perform gradient descent step\n",
        "            optimizer.apply_gradients(zip(grad_theta, self.model.trainable_variables))\n",
        "            return loss\n",
        "\n",
        "        for i in range(N):\n",
        "\n",
        "            loss = train_step()\n",
        "\n",
        "            self.current_loss = loss.numpy()\n",
        "            self.callback()\n",
        "\n",
        "    def callback(self, xr=None):\n",
        "        lambd1 = self.model.lambd1.numpy()\n",
        "        self.model.lambd1_list.append(lambd1)\n",
        "\n",
        "        lambd2 = self.model.lambd2.numpy()\n",
        "        self.model.lambd2_list.append(lambd2)\n",
        "\n",
        "        if self.iter % 100 == 0:\n",
        "            print('It {:05d}: loss = {:10.8e} lambda1 = {:10.8e} lambda2 = {:10.8e}'.format(self.iter, self.current_loss, lambd1, lambd2))\n",
        "\n",
        "        self.hist.append(self.current_loss)\n",
        "        self.iter += 1\n",
        "\n",
        "\n",
        "    # def plot_solution(self, **kwargs):\n",
        "    #     N = 411\n",
        "    #     tspace = np.linspace(self.model.lb[0], self.model.ub[0], N)\n",
        "    #     xspace = np.linspace(self.model.lb[1], self.model.ub[1], N)\n",
        "    #     yspace = np.linspace(self.model.lb[2], self.model.ub[2], N)\n",
        "    #     T, X, Y = np.meshgrid(tspace, xspace, yspace)\n",
        "    #     Xgrid = np.vstack([T.flatten(),X.flatten(),Y.flatten()]).T\n",
        "    #     upred = self.model(tf.cast(Xgrid,DTYPE))\n",
        "    #     U = upred.numpy().reshape(N,N)\n",
        "    #     fig = plt.figure(figsize=(9,6))\n",
        "    #     ax = fig.add_subplot(111, projection='3d')\n",
        "    #     ax.plot_surface(T, X, Y, U, cmap='viridis', **kwargs)\n",
        "    #     ax.set_xlabel('$t$')\n",
        "    #     ax.set_ylabel('$x$')\n",
        "    #     ax.set_zlabel('$u_\\\\theta(t,x)$')\n",
        "    #     ax.view_init(35,35)\n",
        "    #     return ax\n",
        "\n",
        "    def plot_loss_history(self, ax=None):\n",
        "        if not ax:\n",
        "            fig = plt.figure(figsize=(7,5))\n",
        "            ax = fig.add_subplot(111)\n",
        "        ax.semilogy(range(len(self.hist)), self.hist,'k-')\n",
        "        ax.set_xlabel('$n_{epoch}$')\n",
        "        ax.set_ylabel('$\\\\phi^{n_{epoch}}$')\n",
        "        return ax\n",
        "\n",
        "    def plot_loss_and_param(self, axs=None):\n",
        "        if axs:\n",
        "            ax1, ax2 = axs\n",
        "            self.plot_loss_history(ax1)\n",
        "        else:\n",
        "            ax1 = self.plot_loss_history()\n",
        "            ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "\n",
        "        # color = 'tab:blue'\n",
        "        ax2.tick_params(axis='y', labelcolor='tab:blue')\n",
        "        ax2.plot(range(len(self.hist)), self.model.lambd1_list,'-',color='tab:blue')\n",
        "        ax2.plot(range(len(self.hist)), self.model.lambd2_list,'-',color='tab:red')\n",
        "        ax2.set_ylabel('$\\\\lambda^{n_{epoch}}$', color='tab:blue')\n",
        "        return (ax1,ax2)"
      ],
      "metadata": {
        "id": "UBZF3jyotPAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize model\n",
        "model = PINNIdentificationNet(lb, ub, num_hidden_layers=2)\n",
        "model.build(input_shape=(None,3))\n",
        "\n",
        "# initialize PINN solver\n",
        "solver = PINNSolver(model, X_r)"
      ],
      "metadata": {
        "id": "BIqJTdChtQJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = tf.keras.optimizers.schedules.PiecewiseConstantDecay([1000,3000],[1e-2,1e-3,5e-4])\n",
        "optim = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "\n",
        "# start timer\n",
        "t0 = time()\n",
        "\n",
        "solver.solve_with_TFoptimizer(optim, X, data, N=6001)\n",
        "\n",
        "# Print computation time\n",
        "print('\\nComputation time: {} seconds'.format(time()-t0))"
      ],
      "metadata": {
        "id": "ppvRGri9tW4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# solver.plot_solution();"
      ],
      "metadata": {
        "id": "2dRrbkuttZxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "solver.plot_loss_history();"
      ],
      "metadata": {
        "id": "1RCO0H91tiNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "solver.plot_loss_and_param();"
      ],
      "metadata": {
        "id": "-xPYl_iqth0J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}