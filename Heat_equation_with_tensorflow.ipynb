{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMM94OAP05wcpTO3X2ZfbdY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yajuna/tensorflow_pde/blob/master/Heat_equation_with_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook solves the polar heat equation in one dimension\n",
        "\n",
        "$\\rho c \\frac{\\partial T}{\\partial t}=\\frac{\\partial k}{\\partial r}\\frac{\\partial T}{\\partial r}+\\frac{k}{r}\\frac{\\partial T}{\\partial r}+k\\frac{\\partial^2 T}{\\partial r^2}+\\text{source terms}$\n",
        "\n",
        "With the assumption that $\\frac{\\partial k}{\\partial r} = 0$, the equation simplifies to\n",
        "\n",
        "$\\rho c \\frac{\\partial T}{\\partial t}=\\frac{k}{r}\\frac{\\partial T}{\\partial r}+k\\frac{\\partial^2 T}{\\partial r^2}+\\text{source terms}$\n",
        "\n",
        "The initial condition is linearly interpolated from the measured core and bark temperatures at $t = 0$. Two boundary conditions are from the measured core and bark temperatures.\n",
        "\n",
        "We aim to solve the inverse problem for determining the parameters in the original continuous PDE.\n",
        "\n",
        "The inverse problem is formulated to be\n",
        "\n",
        "$\\frac{\\partial T}{\\partial t}=\\lambda_1\\frac{\\partial T}{\\partial r}+\\lambda_2\\frac{\\partial^2 T}{\\partial r^2}+\\lambda_3$\n",
        "\n",
        "and the Physics information is\n",
        "\n",
        "$\\text{residual} = \\frac{\\partial T}{\\partial t}-\\lambda_1\\frac{\\partial T}{\\partial r}-\\lambda_2\\frac{\\partial^2 T}{\\partial r^2}-\\lambda_3$\n"
      ],
      "metadata": {
        "id": "AgIpLMPFGGqp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gzL23xJFGFnJ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set data type and hyperparameters\n",
        "# import data\n",
        "\n",
        "DTYPE = 'float32'\n",
        "tf.keras.backend.set_floatx(DTYPE)\n",
        "\n",
        "EPOCH = 5000\n",
        "\n",
        "##### measured tree temperature for initial and boundary conditions. Need fixing\n",
        "# colnames_tree_temp = ['datetime', 's45_1', 'e9_1', 'n135_1','e45_2', 'n9_2', 'w135_2', 'n45_3', 'w9_3','s135_3', 'w_ext_35']\n",
        "# url1 = \"https://raw.githubusercontent.com/yajuna/linearRegression/master/Tree_Temp_Values_OCT21_to_OCT28_2022.xlsx\"\n",
        "# dataTemp = pandas.read_excel(url1,names=colnames_tree_temp)\n",
        "\n",
        "# train_tree_temp_index = 416 - 2\n",
        "\n",
        "# train_interp_temp_size = train_tree_temp_index\n",
        "\n",
        "# ### Initial and boundary conditions\n",
        "# # core temp is west, at 13.5cm, at 2m high\n",
        "# test_coreTemp = np.array(dataTemp.s135_3[train_tree_temp_index: test_tree_temp_index])+ 273.15\n",
        "# # West, at 9cm, at 3m high\n",
        "# test_midTemp1 = np.array(dataTemp.w9_3[train_tree_temp_index: test_tree_temp_index])+ 273.15\n",
        "# # North, at 4.5cm, at 3m high\n",
        "# test_midTemp2 = np.array(dataTemp.n45_3[train_tree_temp_index: test_tree_temp_index])+ 273.15\n",
        "# # bark temp is West, at bark, at 3.5m high\n",
        "# test_barkTemp = np.array(dataTemp.w_ext_35[train_tree_temp_index: test_tree_temp_index])+ 273.15\n",
        "\n",
        "# # linear interpolate the measured temperature\n",
        "# test_coreTemp = np. interp(time, np.linspace(0,24,test_interp_temp_size),test_coreTemp)\n",
        "# test_midTemp1 = np. interp(time, np.linspace(0,24,test_interp_temp_size),test_midTemp1)\n",
        "# test_midTemp2 = np. interp(time, np.linspace(0,24,test_interp_temp_size),test_midTemp2)\n",
        "# test_barkTemp = np. interp(time, np.linspace(0,24,test_interp_temp_size),test_barkTemp)\n",
        "\n",
        "\n",
        "# initTemp = np.array([test_coreTemp[0], test_midTemp1[0], test_midTemp2[0], test_barkTemp[0]])\n",
        "# init_temp = np.interp(np.linspace(0,radius,n_x), np.linspace(0,radius,initTemp.size),initTemp)"
      ],
      "metadata": {
        "id": "g5DmNcw3JbCK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linearly interpolate initial and boundary data according to the generated time and space collocation points."
      ],
      "metadata": {
        "id": "qrFTcU6kTv4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set number of data points\n",
        "N_0 = 500 # number of points in space\n",
        "N_b = 500 # number of points in time\n",
        "N_r = 100000\n",
        "\n",
        "# Set boundary\n",
        "tmin = 0.\n",
        "tmax = 24.\n",
        "xmin = 0.\n",
        "xmax = 0.135\n",
        "\n",
        "# Lower bounds in time and space\n",
        "lb = tf.constant([tmin, xmin], dtype=DTYPE)\n",
        "# Upper bounds in time and space\n",
        "ub = tf.constant([tmax, xmax], dtype=DTYPE)\n",
        "\n",
        "# Set random seed for reproducible results\n",
        "tf.random.set_seed(0)\n",
        "\n",
        "# Draw uniform sample points for initial boundary data; need N_0 == N_b for concat\n",
        "t_0 = tf.ones((N_0,1), dtype=DTYPE)*lb[0]\n",
        "x_0 = tf.random.uniform((N_0,1), lb[1], ub[1], dtype=DTYPE)\n",
        "X_0 = tf.concat([t_0, x_0], axis=1)\n",
        "\n",
        "# initial condition\n",
        "u_0 = TBD\n",
        "\n",
        "# Boundary data- we compare left and right boundary at give time steps.\n",
        "t_b = tf.random.uniform((N_b,1), lb[0], ub[0], dtype=DTYPE)\n",
        "x_lb = tf.ones((N_b,1), dtype=DTYPE)*lb[1]\n",
        "x_ub = tf.ones((N_b,1), dtype=DTYPE)*ub[1]\n",
        "X_lb = tf.concat([t_b, x_lb], axis=1)\n",
        "X_ub = tf.concat([t_b, x_ub], axis=1)\n",
        "\n",
        "# boundary conditions are core and bark\n",
        "u_lb = TBD\n",
        "u_ub = TBD\n",
        "\n",
        "# Draw uniformly sampled collocation points\n",
        "t_r = tf.random.uniform((N_r,1), lb[0], ub[0], dtype=DTYPE)\n",
        "x_r = tf.random.uniform((N_r,1), lb[1], ub[1], dtype=DTYPE)\n",
        "X_r = tf.concat([t_r, x_r], axis=1)\n",
        "\n",
        "# # Collect boundary and inital data in lists\n",
        "# X_data = [X_0, X_b]\n",
        "# u_data = [u_0, u_b]"
      ],
      "metadata": {
        "id": "h7_brf6eU9q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot initial and boundary data; plot collocation data"
      ],
      "metadata": {
        "id": "GpPdYSJ_5IX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(9,6))\n",
        "plt.scatter(t_0, x_0, c=u_0, marker='X', vmin=-1, vmax=1)\n",
        "plt.scatter(t_b, x_lb, c=u_lb, marker='X', vmin=-1, vmax=1)\n",
        "plt.scatter(t_b, x_ub, c=u_ub, marker='X', vmin=-1, vmax=1)\n",
        "plt.scatter(t_r, x_r, c='r', marker='.', alpha=0.1)\n",
        "plt.xlabel('$t$')\n",
        "plt.ylabel('$x$')\n",
        "\n",
        "plt.title('Positions of collocation points and boundary data');\n",
        "#plt.savefig('Xdata_heat.pdf', bbox_inches='tight', dpi=300)"
      ],
      "metadata": {
        "id": "rBDWQxGB5Nit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class implementation of PINN. Derive `PINN_NeuralNet` from `tf.keras.Model`.\n",
        "\n",
        "Required arguments are the lower bound `lb` and upper bound `ub`. This is a general neural net that is equation independent."
      ],
      "metadata": {
        "id": "m4H4_4S65fX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model architecture\n",
        "\n",
        "class PINN_NeuralNet(tf.keras.Model):\n",
        "  \"\"\"Basic architecture of the PINN model\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, lb, ub,\n",
        "               output_dim = 1,\n",
        "               num_hidden_layers = 8,\n",
        "               num_neurons_per_layer = 20,\n",
        "               activation = 'tanh',\n",
        "               kernel_initializer = 'glorot_normal',\n",
        "               **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "\n",
        "    self.num_hidden_layers = num_hidden_layers\n",
        "    self.output_dim = output_dim\n",
        "    self.lb = lb\n",
        "    self.ub = ub\n",
        "\n",
        "    # Define NN architecture\n",
        "    self.scale = tf.keras.layers.Lambda(\n",
        "            lambda x: 2.0*(x - lb)/(ub - lb) - 1.0)\n",
        "    self.hidden = [tf.keras.layers.Dense(num_neurons_per_layer,\n",
        "                             activation=tf.keras.activations.get(activation),\n",
        "                             kernel_initializer=kernel_initializer)\n",
        "                           for _ in range(self.num_hidden_layers)]\n",
        "    self.out = tf.keras.layers.Dense(output_dim)\n",
        "\n",
        "  def call(self, X):\n",
        "    \"\"\"\n",
        "    Forward-pass thru NN\n",
        "    \"\"\"\n",
        "    Z = self.scale(X)\n",
        "    for i in range(self.num_hidden_layers):\n",
        "      Z = self.hidden[i](Z)\n",
        "    return self.out(Z)"
      ],
      "metadata": {
        "id": "j0dlCK036K5N"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define base class `PINNSolver`. This is equation dependent. Components to customize are\n",
        "\n",
        "1. get_r <---- modify what derivatives are computed\n",
        "2. loss_fn <--- modify the boundary conditions\n",
        "3. fun_r <--- residual of the PDE\n",
        "4. should check all functions if boundary data were changed\n",
        "\n",
        "Here we only consider the method based on tensorflow optimizer object as input. The [original notebook](https://colab.research.google.com/github/janblechschmidt/PDEsByNNs/blob/main/PINN_Solver.ipynb#scrollTo=wcOkamgfZEks) though, also has method based on SciPy's LBFGS method."
      ],
      "metadata": {
        "id": "Tk8dBKP8TNZT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8PNryTZZEks"
      },
      "outputs": [],
      "source": [
        "class PINNSolver():\n",
        "    def __init__(self, X_r):\n",
        "        self.model = model\n",
        "\n",
        "        # Store collocation points, separate t and x\n",
        "        self.t = X_r[:,0:1]\n",
        "        self.x = X_r[:,1:2]\n",
        "\n",
        "        # Initialize history of losses and global iteration counter\n",
        "        self.hist = []\n",
        "        self.iter = 0\n",
        "\n",
        "    def get_r(self):\n",
        "\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            # Watch variables representing t and x during this GradientTape\n",
        "            tape.watch(self.t)\n",
        "            tape.watch(self.x)\n",
        "\n",
        "            # Compute current values u(t,x)\n",
        "            u = self.model(tf.stack([self.t[:,0], self.x[:,0]], axis=1))\n",
        "\n",
        "            u_x = tape.gradient(u, self.x)\n",
        "\n",
        "        u_t = tape.gradient(u, self.t)\n",
        "        u_xx = tape.gradient(u_x, self.x)\n",
        "\n",
        "        del tape\n",
        "\n",
        "        return self.fun_r(self.t, self.x, u, u_t, u_x, u_xx)\n",
        "\n",
        "\n",
        "    def loss_fn(self, X, u):\n",
        "\n",
        "        # Compute phi_r\n",
        "        r = self.get_r()\n",
        "        phi_r = tf.reduce_mean(tf.square(r))\n",
        "\n",
        "        # Initialize loss\n",
        "        loss = phi_r\n",
        "\n",
        "        # Add phi_0 and phi_b to the loss\n",
        "        for i in range(len(X)):\n",
        "            u_pred = self.model(X[i])\n",
        "            loss += tf.reduce_mean(tf.square(u[i] - u_pred))\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def get_grad(self, X, u):\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            # This tape is for derivatives with\n",
        "            # respect to trainable variables\n",
        "            tape.watch(self.model.trainable_variables)\n",
        "            loss = self.loss_fn(X, u)\n",
        "\n",
        "        g = tape.gradient(loss, self.model.trainable_variables)\n",
        "        del tape\n",
        "\n",
        "        return loss, g\n",
        "\n",
        "\n",
        "    def fun_r(self, t, x, u, u_t, u_x, u_xx):\n",
        "        \"\"\"Residual of the PDE\"\"\"\n",
        "        return u_t + u * u_x - viscosity * u_xx\n",
        "        # return u_t - lambd1 * u_x - lambd2 * u_xx - lambd3\n",
        "\n",
        "    def solve_with_TFoptimizer(self, optimizer, X, u, N=1001):\n",
        "        \"\"\"This method performs a gradient descent type optimization.\"\"\"\n",
        "\n",
        "        @tf.function\n",
        "        def train_step():\n",
        "            loss, grad_theta = self.get_grad(X, u)\n",
        "\n",
        "            # Perform gradient descent step\n",
        "            optimizer.apply_gradients(zip(grad_theta, self.model.trainable_variables))\n",
        "            return loss\n",
        "\n",
        "        for i in range(N):\n",
        "\n",
        "            loss = train_step()\n",
        "\n",
        "            self.current_loss = loss.numpy()\n",
        "            self.callback()\n",
        "\n",
        "\n",
        "    def callback(self, xr=None):\n",
        "        if self.iter % 50 == 0:\n",
        "            print('It {:05d}: loss = {:10.8e}'.format(self.iter,self.current_loss))\n",
        "        self.hist.append(self.current_loss)\n",
        "        self.iter+=1\n",
        "\n",
        "\n",
        "    def plot_solution(self, **kwargs):\n",
        "        N = 600\n",
        "        tspace = np.linspace(self.model.lb[0], self.model.ub[0], N+1)\n",
        "        xspace = np.linspace(self.model.lb[1], self.model.ub[1], N+1)\n",
        "        T, X = np.meshgrid(tspace, xspace)\n",
        "        Xgrid = np.vstack([T.flatten(),X.flatten()]).T\n",
        "        upred = self.model(tf.cast(Xgrid,DTYPE))\n",
        "        U = upred.numpy().reshape(N+1,N+1)\n",
        "        fig = plt.figure(figsize=(9,6))\n",
        "        ax = fig.add_subplot(111, projection='3d')\n",
        "        ax.plot_surface(T, X, U, cmap='viridis', **kwargs)\n",
        "        ax.set_xlabel('$t$')\n",
        "        ax.set_ylabel('$x$')\n",
        "        ax.set_zlabel('$u_{\\theta(t,x)$}')\n",
        "        ax.view_init(35,35)\n",
        "        return ax\n",
        "\n",
        "    def plot_loss_history(self, ax=None):\n",
        "        if not ax:\n",
        "            fig = plt.figure(figsize=(7,5))\n",
        "            ax = fig.add_subplot(111)\n",
        "        ax.semilogy(range(len(self.hist)), self.hist,'k-')\n",
        "        ax.set_xlabel('$n_{epoch}$')\n",
        "        ax.set_ylabel('$\\\\phi^{n_{epoch}}$')\n",
        "        return ax"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Derive heat solver class with customized residual, as well as initial and boundary conditions, and gradients."
      ],
      "metadata": {
        "id": "vGzUy1W5S2eh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HeatPINNSolver(PINNSolver):"
      ],
      "metadata": {
        "id": "Vh1OYEozTiXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solve the equation with the two classes PINN_NeuralNet and PINNSolver\n",
        "\n",
        "This is the forward problem"
      ],
      "metadata": {
        "id": "RoEHg_EUyxDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize model\n",
        "model = PINN_NeuralNet(lb, ub)\n",
        "model.build(input_shape=(None,2))\n",
        "\n",
        "# initialize PINN solver\n",
        "solver = HeatPINNSolver(model, X_r)"
      ],
      "metadata": {
        "id": "50yxQSRfzKnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start training"
      ],
      "metadata": {
        "id": "esTT6KY-UDx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = tf.keras.optimizers.schedules.PiecewiseConstantDecay([1000,3000],[1e-2,1e-3,5e-4])\n",
        "optim = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "\n",
        "# start timer\n",
        "t0 = time()\n",
        "solver.solve_with_TFoptimizer(optim, X_data, u_data, N=4001)\n",
        "\n",
        "# Print computation time\n",
        "print('\\nComputation time: {} seconds'.format(time()-t0))"
      ],
      "metadata": {
        "id": "1Cd0oEw9UF9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot solution and loss history"
      ],
      "metadata": {
        "id": "y2ucpOyq3IVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "solver.plot_solution();\n",
        "solver.plot_loss_history();"
      ],
      "metadata": {
        "id": "LxXD05Be3LYP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}